{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from scipy.stats import pearsonr, sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_math_verbal(conn_mat_filename: str, general_scores_filename: str, math_scores_filename: str, verbal_scores_filename: str):\n",
    "    Glasser_conn_mat = np.load(conn_mat_filename)\n",
    "\n",
    "    # get upper triangle indices, without diagonal 0 (k = 1 starts from the k' diagonal)\n",
    "    indices = np.triu_indices(360, k=1)\n",
    "\n",
    "    # create X: rows for subjects, and flattened upper triangle mat for each subject\n",
    "    X = []\n",
    "    for i in range(Glasser_conn_mat.shape[2]):\n",
    "        X.append(Glasser_conn_mat[:, :, i][indices])\n",
    "    # convert X to data frame for pipeline parameters\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    # read scores\n",
    "    y = pd.read_csv(general_scores_filename, header=None).to_numpy()\n",
    "    y_math = pd.read_csv(math_scores_filename, header=None).to_numpy()\n",
    "    y_verbal = pd.read_csv(verbal_scores_filename, header=None).to_numpy()\n",
    "\n",
    "    return X, y, y_math, y_verbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_math, y_verbal= get_X_y_math_verbal(\n",
    "    conn_mat_filename=\"data/Glasser_conn_mat_158_subj.npy\",\n",
    "    general_scores_filename=\"data/general_scores_158_subj.csv\",\n",
    "    math_scores_filename=\"data/math_scores_158_subj.csv\",\n",
    "    verbal_scores_filename=\"data/verbal_scores_158_subj.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>64610</th>\n",
       "      <th>64611</th>\n",
       "      <th>64612</th>\n",
       "      <th>64613</th>\n",
       "      <th>64614</th>\n",
       "      <th>64615</th>\n",
       "      <th>64616</th>\n",
       "      <th>64617</th>\n",
       "      <th>64618</th>\n",
       "      <th>64619</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256043</td>\n",
       "      <td>0.543582</td>\n",
       "      <td>0.834341</td>\n",
       "      <td>0.737259</td>\n",
       "      <td>0.611785</td>\n",
       "      <td>0.551843</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.506335</td>\n",
       "      <td>0.347711</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048507</td>\n",
       "      <td>-0.001441</td>\n",
       "      <td>0.037499</td>\n",
       "      <td>0.057737</td>\n",
       "      <td>0.108180</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.042079</td>\n",
       "      <td>0.084301</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>0.307135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483221</td>\n",
       "      <td>0.612067</td>\n",
       "      <td>0.912712</td>\n",
       "      <td>0.845826</td>\n",
       "      <td>0.808821</td>\n",
       "      <td>0.462722</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.297347</td>\n",
       "      <td>0.760023</td>\n",
       "      <td>0.656678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455484</td>\n",
       "      <td>0.171413</td>\n",
       "      <td>0.093261</td>\n",
       "      <td>0.365236</td>\n",
       "      <td>0.236431</td>\n",
       "      <td>0.193829</td>\n",
       "      <td>0.247808</td>\n",
       "      <td>0.266242</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.532271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.126272</td>\n",
       "      <td>0.541725</td>\n",
       "      <td>0.894314</td>\n",
       "      <td>0.881399</td>\n",
       "      <td>0.768822</td>\n",
       "      <td>0.541432</td>\n",
       "      <td>0.282807</td>\n",
       "      <td>0.175312</td>\n",
       "      <td>0.360123</td>\n",
       "      <td>0.392476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291799</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0.026356</td>\n",
       "      <td>0.229688</td>\n",
       "      <td>0.116440</td>\n",
       "      <td>0.049035</td>\n",
       "      <td>0.071814</td>\n",
       "      <td>0.219577</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.439387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528645</td>\n",
       "      <td>0.548732</td>\n",
       "      <td>0.897949</td>\n",
       "      <td>0.874365</td>\n",
       "      <td>0.722720</td>\n",
       "      <td>0.452277</td>\n",
       "      <td>0.589948</td>\n",
       "      <td>0.519460</td>\n",
       "      <td>0.393255</td>\n",
       "      <td>0.331269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277162</td>\n",
       "      <td>0.061410</td>\n",
       "      <td>0.055927</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.063941</td>\n",
       "      <td>0.240621</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.136225</td>\n",
       "      <td>0.082756</td>\n",
       "      <td>0.281293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.408504</td>\n",
       "      <td>0.533769</td>\n",
       "      <td>0.918164</td>\n",
       "      <td>0.885054</td>\n",
       "      <td>0.722196</td>\n",
       "      <td>0.653343</td>\n",
       "      <td>0.433824</td>\n",
       "      <td>-0.006783</td>\n",
       "      <td>0.548261</td>\n",
       "      <td>0.341645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194007</td>\n",
       "      <td>-0.084169</td>\n",
       "      <td>-0.293965</td>\n",
       "      <td>-0.067129</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>-0.066016</td>\n",
       "      <td>0.092298</td>\n",
       "      <td>0.061617</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.311022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.497834</td>\n",
       "      <td>0.592031</td>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.886041</td>\n",
       "      <td>0.737326</td>\n",
       "      <td>0.665670</td>\n",
       "      <td>0.324835</td>\n",
       "      <td>0.187993</td>\n",
       "      <td>0.534930</td>\n",
       "      <td>0.465906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435125</td>\n",
       "      <td>0.082796</td>\n",
       "      <td>0.125401</td>\n",
       "      <td>0.225401</td>\n",
       "      <td>0.045384</td>\n",
       "      <td>0.137809</td>\n",
       "      <td>0.239056</td>\n",
       "      <td>0.178493</td>\n",
       "      <td>0.124486</td>\n",
       "      <td>0.334965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.274340</td>\n",
       "      <td>0.601339</td>\n",
       "      <td>0.899841</td>\n",
       "      <td>0.832969</td>\n",
       "      <td>0.679898</td>\n",
       "      <td>0.506748</td>\n",
       "      <td>0.209305</td>\n",
       "      <td>0.273583</td>\n",
       "      <td>0.391672</td>\n",
       "      <td>0.145301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274637</td>\n",
       "      <td>0.080526</td>\n",
       "      <td>0.021162</td>\n",
       "      <td>0.204128</td>\n",
       "      <td>0.080962</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.177067</td>\n",
       "      <td>0.244266</td>\n",
       "      <td>0.238470</td>\n",
       "      <td>0.499744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.649097</td>\n",
       "      <td>0.548860</td>\n",
       "      <td>0.792040</td>\n",
       "      <td>0.734714</td>\n",
       "      <td>0.501993</td>\n",
       "      <td>0.564024</td>\n",
       "      <td>0.376806</td>\n",
       "      <td>0.250711</td>\n",
       "      <td>0.529989</td>\n",
       "      <td>0.315082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>0.202375</td>\n",
       "      <td>-0.087569</td>\n",
       "      <td>-0.172030</td>\n",
       "      <td>0.112162</td>\n",
       "      <td>0.011920</td>\n",
       "      <td>-0.065025</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>0.059129</td>\n",
       "      <td>0.414311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.457167</td>\n",
       "      <td>0.697228</td>\n",
       "      <td>0.949361</td>\n",
       "      <td>0.923404</td>\n",
       "      <td>0.861765</td>\n",
       "      <td>0.720488</td>\n",
       "      <td>0.334928</td>\n",
       "      <td>0.192592</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>0.459623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261736</td>\n",
       "      <td>0.200122</td>\n",
       "      <td>0.139826</td>\n",
       "      <td>0.057603</td>\n",
       "      <td>0.277383</td>\n",
       "      <td>0.374788</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.280210</td>\n",
       "      <td>0.196362</td>\n",
       "      <td>0.292409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.206464</td>\n",
       "      <td>0.591203</td>\n",
       "      <td>0.831999</td>\n",
       "      <td>0.796237</td>\n",
       "      <td>0.584414</td>\n",
       "      <td>0.506734</td>\n",
       "      <td>0.296378</td>\n",
       "      <td>0.323051</td>\n",
       "      <td>0.333396</td>\n",
       "      <td>0.076793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570339</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>0.088419</td>\n",
       "      <td>0.147588</td>\n",
       "      <td>0.335105</td>\n",
       "      <td>0.178705</td>\n",
       "      <td>0.190511</td>\n",
       "      <td>0.100918</td>\n",
       "      <td>0.140988</td>\n",
       "      <td>0.321525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows Ã— 64620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6      \\\n",
       "0    0.256043  0.543582  0.834341  0.737259  0.611785  0.551843  0.268657   \n",
       "1    0.483221  0.612067  0.912712  0.845826  0.808821  0.462722  0.192100   \n",
       "2    0.126272  0.541725  0.894314  0.881399  0.768822  0.541432  0.282807   \n",
       "3    0.528645  0.548732  0.897949  0.874365  0.722720  0.452277  0.589948   \n",
       "4    0.408504  0.533769  0.918164  0.885054  0.722196  0.653343  0.433824   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "153  0.497834  0.592031  0.945841  0.886041  0.737326  0.665670  0.324835   \n",
       "154  0.274340  0.601339  0.899841  0.832969  0.679898  0.506748  0.209305   \n",
       "155  0.649097  0.548860  0.792040  0.734714  0.501993  0.564024  0.376806   \n",
       "156  0.457167  0.697228  0.949361  0.923404  0.861765  0.720488  0.334928   \n",
       "157  0.206464  0.591203  0.831999  0.796237  0.584414  0.506734  0.296378   \n",
       "\n",
       "        7         8         9      ...     64610     64611     64612  \\\n",
       "0    0.506335  0.347711  0.313753  ...  0.048507 -0.001441  0.037499   \n",
       "1    0.297347  0.760023  0.656678  ...  0.455484  0.171413  0.093261   \n",
       "2    0.175312  0.360123  0.392476  ...  0.291799  0.033146  0.026356   \n",
       "3    0.519460  0.393255  0.331269  ...  0.277162  0.061410  0.055927   \n",
       "4   -0.006783  0.548261  0.341645  ...  0.194007 -0.084169 -0.293965   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "153  0.187993  0.534930  0.465906  ...  0.435125  0.082796  0.125401   \n",
       "154  0.273583  0.391672  0.145301  ...  0.274637  0.080526  0.021162   \n",
       "155  0.250711  0.529989  0.315082  ...  0.481008  0.202375 -0.087569   \n",
       "156  0.192592  0.507035  0.459623  ...  0.261736  0.200122  0.139826   \n",
       "157  0.323051  0.333396  0.076793  ...  0.570339  0.149866  0.088419   \n",
       "\n",
       "        64613     64614     64615     64616     64617     64618     64619  \n",
       "0    0.057737  0.108180  0.056225  0.042079  0.084301  0.041814  0.307135  \n",
       "1    0.365236  0.236431  0.193829  0.247808  0.266242  0.295980  0.532271  \n",
       "2    0.229688  0.116440  0.049035  0.071814  0.219577  0.078079  0.439387  \n",
       "3    0.003119  0.063941  0.240621  0.062928  0.136225  0.082756  0.281293  \n",
       "4   -0.067129  0.015106 -0.066016  0.092298  0.061617  0.007905  0.311022  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "153  0.225401  0.045384  0.137809  0.239056  0.178493  0.124486  0.334965  \n",
       "154  0.204128  0.080962  0.033422  0.177067  0.244266  0.238470  0.499744  \n",
       "155 -0.172030  0.112162  0.011920 -0.065025 -0.027739  0.059129  0.414311  \n",
       "156  0.057603  0.277383  0.374788  0.009510  0.280210  0.196362  0.292409  \n",
       "157  0.147588  0.335105  0.178705  0.190511  0.100918  0.140988  0.321525  \n",
       "\n",
       "[158 rows x 64620 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[698.],\n",
       "       [623.],\n",
       "       [664.],\n",
       "       [776.],\n",
       "       [663.],\n",
       "       [620.],\n",
       "       [698.],\n",
       "       [770.],\n",
       "       [729.],\n",
       "       [732.],\n",
       "       [750.],\n",
       "       [600.],\n",
       "       [730.],\n",
       "       [667.],\n",
       "       [595.],\n",
       "       [697.],\n",
       "       [672.],\n",
       "       [699.],\n",
       "       [728.],\n",
       "       [581.],\n",
       "       [689.],\n",
       "       [650.],\n",
       "       [729.],\n",
       "       [726.],\n",
       "       [742.],\n",
       "       [695.],\n",
       "       [741.],\n",
       "       [695.],\n",
       "       [577.],\n",
       "       [600.],\n",
       "       [664.],\n",
       "       [712.],\n",
       "       [729.],\n",
       "       [734.],\n",
       "       [745.],\n",
       "       [647.],\n",
       "       [709.],\n",
       "       [670.],\n",
       "       [747.],\n",
       "       [671.],\n",
       "       [596.],\n",
       "       [738.],\n",
       "       [786.],\n",
       "       [706.],\n",
       "       [689.],\n",
       "       [670.],\n",
       "       [780.],\n",
       "       [698.],\n",
       "       [663.],\n",
       "       [734.],\n",
       "       [667.],\n",
       "       [723.],\n",
       "       [768.],\n",
       "       [750.],\n",
       "       [740.],\n",
       "       [738.],\n",
       "       [734.],\n",
       "       [729.],\n",
       "       [745.],\n",
       "       [585.],\n",
       "       [692.],\n",
       "       [669.],\n",
       "       [737.],\n",
       "       [711.],\n",
       "       [730.],\n",
       "       [728.],\n",
       "       [641.],\n",
       "       [698.],\n",
       "       [763.],\n",
       "       [697.],\n",
       "       [685.],\n",
       "       [718.],\n",
       "       [678.],\n",
       "       [730.],\n",
       "       [633.],\n",
       "       [640.],\n",
       "       [680.],\n",
       "       [734.],\n",
       "       [752.],\n",
       "       [693.],\n",
       "       [683.],\n",
       "       [709.],\n",
       "       [728.],\n",
       "       [763.],\n",
       "       [710.],\n",
       "       [678.],\n",
       "       [690.],\n",
       "       [677.],\n",
       "       [719.],\n",
       "       [669.],\n",
       "       [730.],\n",
       "       [732.],\n",
       "       [710.],\n",
       "       [695.],\n",
       "       [756.],\n",
       "       [703.],\n",
       "       [646.],\n",
       "       [700.],\n",
       "       [727.],\n",
       "       [681.],\n",
       "       [687.],\n",
       "       [685.],\n",
       "       [759.],\n",
       "       [625.],\n",
       "       [732.],\n",
       "       [720.],\n",
       "       [624.],\n",
       "       [661.],\n",
       "       [776.],\n",
       "       [747.],\n",
       "       [756.],\n",
       "       [725.],\n",
       "       [640.],\n",
       "       [719.],\n",
       "       [680.],\n",
       "       [680.],\n",
       "       [734.],\n",
       "       [723.],\n",
       "       [708.],\n",
       "       [726.],\n",
       "       [714.],\n",
       "       [711.],\n",
       "       [657.],\n",
       "       [649.],\n",
       "       [736.],\n",
       "       [700.],\n",
       "       [682.],\n",
       "       [540.],\n",
       "       [642.],\n",
       "       [603.],\n",
       "       [655.],\n",
       "       [622.],\n",
       "       [670.],\n",
       "       [543.],\n",
       "       [591.],\n",
       "       [792.],\n",
       "       [668.],\n",
       "       [634.],\n",
       "       [656.],\n",
       "       [447.],\n",
       "       [633.],\n",
       "       [657.],\n",
       "       [650.],\n",
       "       [518.],\n",
       "       [581.],\n",
       "       [635.],\n",
       "       [573.],\n",
       "       [625.],\n",
       "       [604.],\n",
       "       [614.],\n",
       "       [664.],\n",
       "       [630.],\n",
       "       [617.],\n",
       "       [547.],\n",
       "       [672.],\n",
       "       [528.],\n",
       "       [540.],\n",
       "       [640.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149.],\n",
       "       [133.],\n",
       "       [134.],\n",
       "       [143.],\n",
       "       [108.],\n",
       "       [110.],\n",
       "       [145.],\n",
       "       [150.],\n",
       "       [135.],\n",
       "       [140.],\n",
       "       [142.],\n",
       "       [120.],\n",
       "       [141.],\n",
       "       [137.],\n",
       "       [106.],\n",
       "       [138.],\n",
       "       [113.],\n",
       "       [138.],\n",
       "       [148.],\n",
       "       [117.],\n",
       "       [145.],\n",
       "       [113.],\n",
       "       [139.],\n",
       "       [130.],\n",
       "       [144.],\n",
       "       [140.],\n",
       "       [138.],\n",
       "       [145.],\n",
       "       [117.],\n",
       "       [ 90.],\n",
       "       [110.],\n",
       "       [129.],\n",
       "       [139.],\n",
       "       [130.],\n",
       "       [145.],\n",
       "       [112.],\n",
       "       [138.],\n",
       "       [132.],\n",
       "       [136.],\n",
       "       [124.],\n",
       "       [110.],\n",
       "       [150.],\n",
       "       [148.],\n",
       "       [138.],\n",
       "       [148.],\n",
       "       [148.],\n",
       "       [150.],\n",
       "       [147.],\n",
       "       [132.],\n",
       "       [145.],\n",
       "       [130.],\n",
       "       [137.],\n",
       "       [148.],\n",
       "       [142.],\n",
       "       [149.],\n",
       "       [140.],\n",
       "       [138.],\n",
       "       [141.],\n",
       "       [135.],\n",
       "       [117.],\n",
       "       [136.],\n",
       "       [125.],\n",
       "       [146.],\n",
       "       [137.],\n",
       "       [150.],\n",
       "       [132.],\n",
       "       [ 99.],\n",
       "       [114.],\n",
       "       [147.],\n",
       "       [141.],\n",
       "       [130.],\n",
       "       [145.],\n",
       "       [124.],\n",
       "       [140.],\n",
       "       [125.],\n",
       "       [150.],\n",
       "       [138.],\n",
       "       [142.],\n",
       "       [146.],\n",
       "       [139.],\n",
       "       [147.],\n",
       "       [128.],\n",
       "       [142.],\n",
       "       [148.],\n",
       "       [148.],\n",
       "       [131.],\n",
       "       [141.],\n",
       "       [131.],\n",
       "       [136.],\n",
       "       [134.],\n",
       "       [143.],\n",
       "       [150.],\n",
       "       [138.],\n",
       "       [122.],\n",
       "       [143.],\n",
       "       [131.],\n",
       "       [124.],\n",
       "       [143.],\n",
       "       [132.],\n",
       "       [132.],\n",
       "       [135.],\n",
       "       [127.],\n",
       "       [147.],\n",
       "       [113.],\n",
       "       [150.],\n",
       "       [136.],\n",
       "       [134.],\n",
       "       [131.],\n",
       "       [148.],\n",
       "       [142.],\n",
       "       [148.],\n",
       "       [136.],\n",
       "       [119.],\n",
       "       [140.],\n",
       "       [133.],\n",
       "       [140.],\n",
       "       [138.],\n",
       "       [142.],\n",
       "       [141.],\n",
       "       [135.],\n",
       "       [126.],\n",
       "       [145.],\n",
       "       [135.],\n",
       "       [114.],\n",
       "       [141.],\n",
       "       [135.],\n",
       "       [146.],\n",
       "       [ 99.],\n",
       "       [140.],\n",
       "       [140.],\n",
       "       [136.],\n",
       "       [143.],\n",
       "       [135.],\n",
       "       [111.],\n",
       "       [120.],\n",
       "       [149.],\n",
       "       [134.],\n",
       "       [118.],\n",
       "       [124.],\n",
       "       [ 90.],\n",
       "       [129.],\n",
       "       [120.],\n",
       "       [117.],\n",
       "       [113.],\n",
       "       [120.],\n",
       "       [130.],\n",
       "       [108.],\n",
       "       [109.],\n",
       "       [127.],\n",
       "       [ 90.],\n",
       "       [134.],\n",
       "       [121.],\n",
       "       [125.],\n",
       "       [115.],\n",
       "       [138.],\n",
       "       [ 97.],\n",
       "       [ 99.],\n",
       "       [ 90.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.],\n",
       "       [121.],\n",
       "       [120.],\n",
       "       [148.],\n",
       "       [142.],\n",
       "       [100.],\n",
       "       [130.],\n",
       "       [135.],\n",
       "       [130.],\n",
       "       [148.],\n",
       "       [143.],\n",
       "       [111.],\n",
       "       [137.],\n",
       "       [148.],\n",
       "       [122.],\n",
       "       [129.],\n",
       "       [145.],\n",
       "       [130.],\n",
       "       [132.],\n",
       "       [105.],\n",
       "       [130.],\n",
       "       [132.],\n",
       "       [134.],\n",
       "       [150.],\n",
       "       [136.],\n",
       "       [120.],\n",
       "       [148.],\n",
       "       [116.],\n",
       "       [113.],\n",
       "       [134.],\n",
       "       [120.],\n",
       "       [145.],\n",
       "       [148.],\n",
       "       [145.],\n",
       "       [142.],\n",
       "       [129.],\n",
       "       [133.],\n",
       "       [111.],\n",
       "       [148.],\n",
       "       [131.],\n",
       "       [117.],\n",
       "       [147.],\n",
       "       [150.],\n",
       "       [130.],\n",
       "       [125.],\n",
       "       [125.],\n",
       "       [148.],\n",
       "       [134.],\n",
       "       [130.],\n",
       "       [132.],\n",
       "       [120.],\n",
       "       [144.],\n",
       "       [147.],\n",
       "       [140.],\n",
       "       [140.],\n",
       "       [140.],\n",
       "       [146.],\n",
       "       [135.],\n",
       "       [145.],\n",
       "       [116.],\n",
       "       [130.],\n",
       "       [134.],\n",
       "       [137.],\n",
       "       [139.],\n",
       "       [145.],\n",
       "       [148.],\n",
       "       [140.],\n",
       "       [146.],\n",
       "       [142.],\n",
       "       [135.],\n",
       "       [150.],\n",
       "       [140.],\n",
       "       [135.],\n",
       "       [150.],\n",
       "       [124.],\n",
       "       [145.],\n",
       "       [125.],\n",
       "       [138.],\n",
       "       [140.],\n",
       "       [131.],\n",
       "       [119.],\n",
       "       [143.],\n",
       "       [139.],\n",
       "       [141.],\n",
       "       [136.],\n",
       "       [124.],\n",
       "       [118.],\n",
       "       [127.],\n",
       "       [137.],\n",
       "       [132.],\n",
       "       [139.],\n",
       "       [133.],\n",
       "       [134.],\n",
       "       [141.],\n",
       "       [149.],\n",
       "       [135.],\n",
       "       [119.],\n",
       "       [130.],\n",
       "       [145.],\n",
       "       [137.],\n",
       "       [138.],\n",
       "       [136.],\n",
       "       [144.],\n",
       "       [128.],\n",
       "       [127.],\n",
       "       [136.],\n",
       "       [119.],\n",
       "       [122.],\n",
       "       [147.],\n",
       "       [144.],\n",
       "       [143.],\n",
       "       [147.],\n",
       "       [124.],\n",
       "       [140.],\n",
       "       [143.],\n",
       "       [126.],\n",
       "       [146.],\n",
       "       [131.],\n",
       "       [133.],\n",
       "       [145.],\n",
       "       [104.],\n",
       "       [139.],\n",
       "       [124.],\n",
       "       [128.],\n",
       "       [136.],\n",
       "       [135.],\n",
       "       [123.],\n",
       "       [120.],\n",
       "       [120.],\n",
       "       [ 90.],\n",
       "       [129.],\n",
       "       [ 91.],\n",
       "       [120.],\n",
       "       [102.],\n",
       "       [102.],\n",
       "       [150.],\n",
       "       [128.],\n",
       "       [125.],\n",
       "       [127.],\n",
       "       [ 95.],\n",
       "       [124.],\n",
       "       [130.],\n",
       "       [128.],\n",
       "       [ 87.],\n",
       "       [130.],\n",
       "       [120.],\n",
       "       [116.],\n",
       "       [123.],\n",
       "       [113.],\n",
       "       [100.],\n",
       "       [128.],\n",
       "       [125.],\n",
       "       [125.],\n",
       "       [121.],\n",
       "       [122.],\n",
       "       [107.],\n",
       "       [120.],\n",
       "       [120.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_verbal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean General Score: 682.69\n",
      "Mean Math Score: 132.18\n",
      "Mean Verbal Score: 130.85\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean General Score: {np.round(np.mean(y), 2)}\")\n",
    "print(f\"Mean Math Score: {np.round(np.mean(y_math), 2)}\")\n",
    "print(f\"Mean Verbal Score: {np.round(np.mean(y_verbal), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation General Score: 60.07\n",
      "Standard deviation Math Score: 14.32\n",
      "Standard deviation Verbal Score: 13.35\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard deviation General Score: {np.round(np.std(y), 2)}\")\n",
    "print(f\"Standard deviation Math Score: {np.round(np.std(y_math), 2)}\")\n",
    "print(f\"Standard deviation Verbal Score: {np.round(np.std(y_verbal), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - General Scores (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.28 -0.67 -0.68 -0.76 -1.81 -1.55 -1.16 -0.62 -1.39 -0.52]\n",
      "mean MSE across folds: 1.04\n",
      "MSE standard error across folds: 0.14\n",
      "Test MSE: 1.47, r: 0.052, p value: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data \n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Math Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-0.58 -0.75 -1.85 -0.69 -1.56 -1.58 -1.47 -0.67 -1.52 -0.65]\n",
      "mean MSE across folds: 1.13\n",
      "MSE standard error across folds: 0.16\n",
      "Test MSE: 1.009, r: 0.203, p value: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_math, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data \n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Verbal Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.47 -1.14 -1.36 -1.   -1.63 -0.72 -1.27 -0.68 -0.86 -0.78]\n",
      "mean MSE across folds: 1.09\n",
      "MSE standard error across folds: 0.11\n",
      "Test MSE: 1.146, r: -0.011, p value: 0.969\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_verbal, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data \n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge - General scores for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.28 -0.67 -0.68 -0.76 -1.81 -1.55 -1.16 -0.62 -1.39 -0.52]\n",
      "mean MSE across folds: 1.04\n",
      "MSE standard error across folds: 0.14\n",
      "Test MSE: 1.47, r: 0.052, p value: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "rdg = Ridge()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(rdg, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data \n",
    "rdg.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = rdg.predict(X_test_pca)\n",
    "test_mse_rdg = mean_squared_error(y_test, y_test_predicted)\n",
    "r_rdg, p_val_rdg = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_rdg, 3)}, r: {np.round(r_rdg, 3)}, p value: {np.round(p_val_rdg, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge - Math scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-0.58 -0.75 -1.85 -0.69 -1.56 -1.58 -1.47 -0.67 -1.52 -0.65]\n",
      "mean MSE across folds: 1.13\n",
      "MSE standard error across folds: 0.16\n",
      "Test MSE: 1.009, r: 0.203, p value: 0.45\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_math, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "rdg = Ridge()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(rdg, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data \n",
    "rdg.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = rdg.predict(X_test_pca)\n",
    "test_mse_rdg = mean_squared_error(y_test, y_test_predicted)\n",
    "r_rdg, p_val_rdg = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_rdg, 3)}, r: {np.round(r_rdg, 3)}, p value: {np.round(p_val_rdg, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge - verbal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.47 -1.14 -1.36 -1.   -1.63 -0.72 -1.27 -0.68 -0.86 -0.78]\n",
      "mean MSE across folds: 1.09\n",
      "MSE standard error across folds: 0.11\n",
      "Test MSE: 1.146, r: -0.011, p value: 0.969\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_verbal, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "rdg = Ridge()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(rdg, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data \n",
    "rdg.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = rdg.predict(X_test_pca)\n",
    "test_mse_rdg = mean_squared_error(y_test, y_test_predicted)\n",
    "r_rdg, p_val_rdg = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_rdg, 3)}, r: {np.round(r_rdg, 3)}, p value: {np.round(p_val_rdg, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso - general scores for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.2  -0.72 -0.79 -0.78 -1.63 -1.59 -1.11 -0.57 -1.35 -0.48]\n",
      "mean MSE across folds: 1.02\n",
      "MSE standard error across folds: 0.13\n",
      "Test MSE: 1.399, r: 0.191, p value: 0.479\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = Lasso()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso - Math scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-0.57 -0.78 -1.57 -0.68 -1.29 -1.35 -1.3  -0.52 -1.47 -0.6 ]\n",
      "mean MSE across folds: 1.01\n",
      "MSE standard error across folds: 0.13\n",
      "Test MSE: 0.991, r: 0.202, p value: 0.452\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_math, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = Lasso()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso - verbal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.43 -1.12 -1.52 -0.93 -1.51 -0.7  -1.23 -0.67 -0.76 -0.68]\n",
      "mean MSE across folds: 1.05\n",
      "MSE standard error across folds: 0.11\n",
      "Test MSE: 1.072, r: 0.072, p value: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_verbal, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = Lasso()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net - general scores for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.22 -0.7  -0.72 -0.78 -1.68 -1.56 -1.11 -0.59 -1.36 -0.5 ]\n",
      "mean MSE across folds: 1.02\n",
      "MSE standard error across folds: 0.13\n",
      "Test MSE: 1.428, r: 0.127, p value: 0.639\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = ElasticNet()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net - math scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-0.58 -0.75 -1.7  -0.69 -1.36 -1.44 -1.38 -0.55 -1.49 -0.61]\n",
      "mean MSE across folds: 1.05\n",
      "MSE standard error across folds: 0.14\n",
      "Test MSE: 1.003, r: 0.195, p value: 0.469\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_math, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = ElasticNet()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net - verbal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.45 -1.14 -1.46 -0.96 -1.56 -0.71 -1.27 -0.68 -0.8  -0.74]\n",
      "mean MSE across folds: 1.08\n",
      "MSE standard error across folds: 0.11\n",
      "Test MSE: 1.11, r: 0.021, p value: 0.939\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_verbal, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "lr = ElasticNet()\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(lr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "lr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = lr.predict(X_test_pca)\n",
    "test_mse_lr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_lr, p_val_lr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_lr, 3)}, r: {np.round(r_lr, 3)}, p value: {np.round(p_val_lr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - general scores for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r:  0.13 , mean p-value:  0.49\n",
      "min MSE: 0.58 in fold 4\n",
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "cross validation negative MSE score:  [-1.12 -0.75 -1.14 -0.75 -1.31 -1.6  -1.05 -0.77 -1.39 -0.35]\n",
      "mean MSE across folds: 1.02\n",
      "MSE standard error across folds: 0.12\n",
      "MSE: 1.389, r: 0.235, p value: 0.381\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=75, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Parameters grid for hyperparameter tuning \n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "r_vec = []\n",
    "p_value_vec = []\n",
    "fold_mse_train = []\n",
    "fold_mse_val = []\n",
    "fold_config = []\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_pca):\n",
    "    X_train_fold, X_val_fold = X_train_pca[train_index], X_train_pca[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    random_forest = RandomForestRegressor(random_state=0)\n",
    "    grid_search = GridSearchCV(\n",
    "        random_forest,\n",
    "        param_grid=param_grid_rf,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Fit and Predict\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    y_train_predicted = best_estimator.predict(X_train_fold)\n",
    "    y_predicted = best_estimator.predict(X_val_fold)\n",
    "    fold_config.append(grid_search.best_params_)\n",
    "    train_mse, val_mse = mean_squared_error(y_train_fold, y_train_predicted), mean_squared_error(y_val_fold, y_predicted)\n",
    "\n",
    "    r, p_value = pearsonr(y_predicted, y_val_fold)\n",
    "    r_vec.append(r)\n",
    "    p_value_vec.append(p_value)\n",
    "    fold_mse_train.append(train_mse)\n",
    "    fold_mse_val.append(val_mse)\n",
    "\n",
    "print(\"mean r: \", np.round(np.mean(r_vec), 2), \", mean p-value: \", np.round(np.mean(p_value_vec), 2))\n",
    "\n",
    "print(f\"min MSE: {np.round(np.min(fold_mse_val), 2)} in fold {np.argmin(fold_mse_val) + 1}\")\n",
    "# Configuration that received the minimal MSE\n",
    "config = fold_config[np.argmin(fold_mse_val)]\n",
    "print(config)\n",
    "\n",
    "# Random Forest Regressor with the most accurate configuration\n",
    "chosen_random_forest = RandomForestRegressor(random_state=0, **config)\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(chosen_random_forest, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "chosen_random_forest.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_pred = chosen_random_forest.predict(X_test_pca)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r, p_value = pearsonr(y_test, y_pred)\n",
    "print(f\"MSE: {np.round(mse, 3)}, r: {np.round(r, 3)}, p value: {np.round(p_value, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - math scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r:  0.18 , mean p-value:  0.51\n",
      "min MSE: 0.38 in fold 5\n",
      "{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "cross validation negative MSE score:  [-0.63 -1.2  -1.69 -0.58 -1.07 -1.48 -0.95 -0.7  -1.47 -0.56]\n",
      "mean MSE across folds: 1.03\n",
      "MSE standard error across folds: 0.13\n",
      "MSE: 0.853, r: 0.66, p value: 0.005\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_math, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=75, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Parameters grid for hyperparameter tuning \n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "r_vec = []\n",
    "p_value_vec = []\n",
    "fold_mse_train = []\n",
    "fold_mse_val = []\n",
    "fold_config = []\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_pca):\n",
    "    X_train_fold, X_val_fold = X_train_pca[train_index], X_train_pca[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    random_forest = RandomForestRegressor(random_state=0)\n",
    "    grid_search = GridSearchCV(\n",
    "        random_forest,\n",
    "        param_grid=param_grid_rf,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Fit and Predict\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    y_train_predicted = best_estimator.predict(X_train_fold)\n",
    "    y_predicted = best_estimator.predict(X_val_fold)\n",
    "    fold_config.append(grid_search.best_params_)\n",
    "    train_mse, val_mse = mean_squared_error(y_train_fold, y_train_predicted), mean_squared_error(y_val_fold, y_predicted)\n",
    "\n",
    "    r, p_value = pearsonr(y_predicted, y_val_fold)\n",
    "    r_vec.append(r)\n",
    "    p_value_vec.append(p_value)\n",
    "    fold_mse_train.append(train_mse)\n",
    "    fold_mse_val.append(val_mse)\n",
    "\n",
    "print(\"mean r: \", np.round(np.mean(r_vec), 2), \", mean p-value: \", np.round(np.mean(p_value_vec), 2))\n",
    "\n",
    "print(f\"min MSE: {np.round(np.min(fold_mse_val), 2)} in fold {np.argmin(fold_mse_val) + 1}\")\n",
    "# Configuration that received the minimal MSE\n",
    "config = fold_config[np.argmin(fold_mse_val)]\n",
    "print(config)\n",
    "\n",
    "# Random Forest Regressor with the most accurate configuration\n",
    "chosen_random_forest = RandomForestRegressor(random_state=0, **config)\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(chosen_random_forest, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "chosen_random_forest.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_pred = chosen_random_forest.predict(X_test_pca)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r, p_value = pearsonr(y_test, y_pred)\n",
    "print(f\"MSE: {np.round(mse, 3)}, r: {np.round(r, 3)}, p value: {np.round(p_value, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - verbal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean r:  0.09 , mean p-value:  0.59\n",
      "min MSE: 0.47 in fold 5\n",
      "{'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "cross validation negative MSE score:  [-1.56 -1.05 -1.64 -0.98 -1.33 -0.74 -1.25 -0.72 -0.62 -0.56]\n",
      "mean MSE across folds: 1.04\n",
      "MSE standard error across folds: 0.12\n",
      "MSE: 1.054, r: 0.33, p value: 0.212\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_verbal, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=75, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Parameters grid for hyperparameter tuning \n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "r_vec = []\n",
    "p_value_vec = []\n",
    "fold_mse_train = []\n",
    "fold_mse_val = []\n",
    "fold_config = []\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_pca):\n",
    "    X_train_fold, X_val_fold = X_train_pca[train_index], X_train_pca[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    random_forest = RandomForestRegressor(random_state=0)\n",
    "    grid_search = GridSearchCV(\n",
    "        random_forest,\n",
    "        param_grid=param_grid_rf,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Fit and Predict\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    y_train_predicted = best_estimator.predict(X_train_fold)\n",
    "    y_predicted = best_estimator.predict(X_val_fold)\n",
    "    fold_config.append(grid_search.best_params_)\n",
    "    train_mse, val_mse = mean_squared_error(y_train_fold, y_train_predicted), mean_squared_error(y_val_fold, y_predicted)\n",
    "\n",
    "    r, p_value = pearsonr(y_predicted, y_val_fold)\n",
    "    r_vec.append(r)\n",
    "    p_value_vec.append(p_value)\n",
    "    fold_mse_train.append(train_mse)\n",
    "    fold_mse_val.append(val_mse)\n",
    "\n",
    "print(\"mean r: \", np.round(np.mean(r_vec), 2), \", mean p-value: \", np.round(np.mean(p_value_vec), 2))\n",
    "\n",
    "print(f\"min MSE: {np.round(np.min(fold_mse_val), 2)} in fold {np.argmin(fold_mse_val) + 1}\")\n",
    "# Configuration that received the minimal MSE\n",
    "config = fold_config[np.argmin(fold_mse_val)]\n",
    "print(config)\n",
    "\n",
    "# Random Forest Regressor with the most accurate configuration\n",
    "chosen_random_forest = RandomForestRegressor(random_state=0, **config)\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(chosen_random_forest, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "chosen_random_forest.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_pred = chosen_random_forest.predict(X_test_pca)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r, p_value = pearsonr(y_test, y_pred)\n",
    "print(f\"MSE: {np.round(mse, 3)}, r: {np.round(r, 3)}, p value: {np.round(p_value, 3)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting - general scores for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.5  -0.6  -1.45 -0.86 -1.44 -1.64 -1.36 -0.82 -1.41 -0.73]\n",
      "mean MSE across folds: 1.18\n",
      "MSE standard error across folds: 0.12\n",
      "Test MSE: 1.358, r: 0.299, p value: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(gbr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "gbr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = gbr.predict(X_test_pca)\n",
    "test_mse_gbr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_gbr, p_val_gbr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_gbr, 3)}, r: {np.round(r_gbr, 3)}, p value: {np.round(p_val_gbr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting - math scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-0.32 -1.26 -2.18 -0.57 -1.44 -1.93 -1.31 -0.71 -1.5  -0.62]\n",
      "mean MSE across folds: 1.18\n",
      "MSE standard error across folds: 0.19\n",
      "Test MSE: 0.903, r: 0.309, p value: 0.244\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_math, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(gbr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "gbr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = gbr.predict(X_test_pca)\n",
    "test_mse_gbr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_gbr, p_val_gbr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_gbr, 3)}, r: {np.round(r_gbr, 3)}, p value: {np.round(p_val_gbr, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting - verbal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation negative MSE score:  [-1.57 -1.24 -2.09 -1.   -1.8  -1.21 -1.7  -0.76 -0.86 -1.48]\n",
      "mean MSE across folds: 1.37\n",
      "MSE standard error across folds: 0.14\n",
      "Test MSE: 1.262, r: -0.203, p value: 0.451\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_verbal, test_size=0.1, random_state=0)\n",
    "\n",
    "# Normalization of features and behavioral scores\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train).ravel()\n",
    "y_test = scaler.transform(y_test).ravel()\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "pca = PCA(n_components=20, svd_solver=\"full\", random_state=0)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "# Apply PCA on the testing data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Report cross validation score across all folds\n",
    "cross_val_score_list = cross_val_score(gbr, X_train_pca, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "print(\"cross validation negative MSE score: \", np.round(cross_val_score_list, 2))\n",
    "print(\"mean MSE across folds:\", np.round(-1 * np.mean(cross_val_score_list), 2))\n",
    "print(\"MSE standard error across folds:\", np.round(sem(cross_val_score_list), 2))\n",
    "\n",
    "# Fit the model to train data\n",
    "gbr.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on unseen test set\n",
    "y_test_predicted = gbr.predict(X_test_pca)\n",
    "test_mse_gbr = mean_squared_error(y_test, y_test_predicted)\n",
    "r_gbr, p_val_gbr = pearsonr(y_test, y_test_predicted)\n",
    "print(f\"Test MSE: {np.round(test_mse_gbr, 3)}, r: {np.round(r_gbr, 3)}, p value: {np.round(p_val_gbr, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
